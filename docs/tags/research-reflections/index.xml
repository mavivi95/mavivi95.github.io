<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research Reflections | Hugo Academic CV Theme</title>
    <link>https://ubiquitous-parakeet-vr9r6r7p47cww7r-1313.app.github.dev/tags/research-reflections/</link>
      <atom:link href="https://ubiquitous-parakeet-vr9r6r7p47cww7r-1313.app.github.dev/tags/research-reflections/index.xml" rel="self" type="application/rss+xml" />
    <description>Research Reflections</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 22 Oct 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ubiquitous-parakeet-vr9r6r7p47cww7r-1313.app.github.dev/media/icon_hu_982c5d63a71b2961.png</url>
      <title>Research Reflections</title>
      <link>https://ubiquitous-parakeet-vr9r6r7p47cww7r-1313.app.github.dev/tags/research-reflections/</link>
    </image>
    
    <item>
      <title>üìö Recommended Readings on Cooperative AI (Vol. 1)</title>
      <link>https://ubiquitous-parakeet-vr9r6r7p47cww7r-1313.app.github.dev/post/lecturas_v1/</link>
      <pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ubiquitous-parakeet-vr9r6r7p47cww7r-1313.app.github.dev/post/lecturas_v1/</guid>
      <description>&lt;p&gt;Cooperative AI is not only a technical challenge but also a question about how to design systems that balance individual incentives and collective welfare. In this first edition, I share a selection of papers that shaped the way I think about cooperation, social dilemmas, and resilience in multi-agent systems.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Open Problems in Cooperative AI ‚Äî Dafoe et al., 2021&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This paper is a research roadmap. It identifies key open questions spanning cooperation between AIs, human‚ÄìAI coordination, communication, and mechanism design.&lt;/p&gt;
&lt;p&gt;üí° Why read it: It&amp;rsquo;s the definitive starting point for researchers who want to contribute to Cooperative AI ‚Äî outlining what remains unsolved and why it matters for global AI safety and governance&lt;/p&gt;



  
  
  
  
  


















  
  
  
  


&lt;div class=&#34;callout flex px-4 py-3 mb-6 rounded-md border-l-4 bg-orange-100 dark:bg-orange-900 border-orange-500&#34; 
     data-callout=&#34;warning&#34; 
     data-callout-metadata=&#34;&#34;&gt;
  &lt;span class=&#34;callout-icon pr-3 pt-1 text-orange-600 dark:text-orange-300&#34;&gt;
    &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt;
  &lt;div class=&#34;callout-content dark:text-neutral-300&#34;&gt;
    &lt;div class=&#34;callout-title font-semibold mb-1&#34;&gt;This page is under construction.&lt;br&gt;&lt;/div&gt;
    &lt;div class=&#34;callout-body&#34;&gt;&lt;p&gt;I&amp;rsquo;m currently setting up this section ‚Äî new posts coming soon! üöß&lt;/p&gt;&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>ü§ñ Reflections from the Cooperative AI Summer School 2025</title>
      <link>https://ubiquitous-parakeet-vr9r6r7p47cww7r-1313.app.github.dev/post/summer-cai/</link>
      <pubDate>Tue, 15 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://ubiquitous-parakeet-vr9r6r7p47cww7r-1313.app.github.dev/post/summer-cai/</guid>
      <description>&lt;h2 id=&#34;a-week-of-cooperation-learning-and-shared-curiosity&#34;&gt;A week of cooperation, learning, and shared curiosity&lt;/h2&gt;
&lt;h4 id=&#34;-overview&#34;&gt;üåç Overview&lt;/h4&gt;
&lt;p&gt;This summer, I had the opportunity to attend the Cooperative AI Summer School 2025, organized by the Cooperative AI Foundation. It took place in Marlow, UK ‚Äî a quiet town surrounded by green landscapes, perfect for a week dedicated to deep discussions about AI, cooperation, and human values. The program combined academic sessions and collaborative activities, structured as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Keynote lectures by leading researchers,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One-to-one meetings and working groups,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Poster sessions on July 10‚Äì11,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A final hands-on challenge session.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;-main-themes-that-inspired-me&#34;&gt;üí° Main themes that inspired me&lt;/h4&gt;
&lt;p&gt;The school brought together researchers from diverse fields‚Äîspanning machine learning, game theory, philosophy, and the social sciences. Despite our different profiles and research agendas, we converged on a shared question:
&lt;em&gt;How can we build AI systems that cooperate effectively with humans and with each other?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Talks ranged from the formal foundations of cooperation and mixed-motive games to the social and ethical dimensions of AI. I was especially inspired by sessions on emergent coordination, multi-agent learning under uncertainty, and resilient collective behaviors. The poster session was equally insightful: work on diplomatic games and AI-mediated negotiation‚Äîparticularly with LLM-based agents‚Äîmade clear where current AI capabilities are heading and what is at stake.&lt;/p&gt;
&lt;p&gt;This trajectory presents both opportunities and risks. It underscores the need to anticipate misalignment behaviors and to advance AI safety by designing systems that incentivize cooperative objectives, align with collective well-being, and support multisector progress across regions.&lt;/p&gt;
&lt;h4 id=&#34;-poster-presentation-and-gif-competition&#34;&gt;üß† Poster Presentation and GIF Competition&lt;/h4&gt;
&lt;p&gt;During the poster sessions, I presented my work titled ‚ÄúCooperative Resilience in Multi-Agent AI Systems: From Definition to Reward Inference.‚Äù The poster summarized my research agenda, which unfolds in four main stages: defining what resilience means within the scope of Cooperative AI; measuring this property in mixed-motive multi-agent systems; understanding what drives agents to exhibit‚Äîor fail to exhibit‚Äîresilient behavior, for example by inferring their underlying rewards or motivations from trajectories evaluated with a resilience metric; and finally, using those insights to design agents that encapsulate this property and foster system-level resilience. The first two stages ‚Äî &lt;strong&gt;definition&lt;/strong&gt; and &lt;strong&gt;measurement&lt;/strong&gt; ‚Äî were developed in detail in my 
, which lays the theoretical and experimental foundation for this line of research.&lt;/p&gt;
&lt;div class=&#34;poster-grid&#34;&gt;
  &lt;div class=&#34;poster-column gif-col&#34;&gt;
    &lt;img src=&#34;gif_animado.gif&#34; alt=&#34;Winning GIF&#34; class=&#34;poster-gif&#34;/&gt;
  &lt;/div&gt;
  &lt;div class=&#34;poster-column&#34;&gt;
    &lt;img src=&#34;img2.jpg&#34; alt=&#34;Presenting the poster&#34; class=&#34;poster-photo&#34;/&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;poster-button-container&#34;&gt;
  &lt;a class=&#34;poster-button&#34; href=&#34;poster.pdf&#34; target=&#34;_blank&#34;&gt;üìÑ View Full Poster (PDF)&lt;/a&gt;
&lt;/div&gt;
&lt;h4 id=&#34;-final-day--collaborative-challenge&#34;&gt;üß© Final Day ‚Äî Collaborative Challenge&lt;/h4&gt;
&lt;p&gt;In the final session, we participated in a hands-on challenge exploring agent properties such as truthfulness and information sharing. Our group proposed an approach to measure truthfulness by analyzing how agents omit relevant information ‚Äî linking naturally with our ongoing research on cooperative resilience and behavioral inference. This session fostered interdisciplinary collaboration, connecting reinforcement learning, behavioral modeling, and ethics.&lt;/p&gt;
&lt;p&gt;This activity raised deep questions about systems with LLM agents. Truthfulness alone is hard to define‚Äîlet alone guarantee‚Äîand it quickly connects to other, more human-like capacities we may be inadvertently promoting in artificial agents. In particular, the ability to &lt;strong&gt;omit information&lt;/strong&gt; is critical: agents might leave things out for strategic, safety-related, or purely accidental reasons. Detecting when omission occurs, and inferring the underlying motivation, becomes a central challenge for evaluation and governance.&lt;/p&gt;
&lt;h4 id=&#34;-connecting-research-and-purpose&#34;&gt;ü§ù Connecting research and purpose&lt;/h4&gt;
&lt;p&gt;Beyond the technical depth, what struck me most was the &lt;strong&gt;community&lt;/strong&gt;. I met researchers and practitioners working on questions closely aligned with my own, and it was energizing to realize how many people around the world are pursuing similar ideas. I had the chance to speak with several of them‚Äîpeople who share a vision for cooperative, reliable AI‚Äîand those conversations were grounding and inspiring. The school fostered an open, reflective atmosphere that blended academic rigor with philosophical curiosity and deeply motivating.&lt;/p&gt;
&lt;h4 id=&#34;-looking-forward&#34;&gt;üå± Looking forward&lt;/h4&gt;
&lt;p&gt;Attending the Cooperative AI Summer School was a truly inspiring experience, scientifically and personally. It strengthened my understanding of cooperation as a fundamental design principle in AI systems and allowed me to connect with the global Cooperative AI community, sharing ideas, building friendships, and finding common research goals.&lt;/p&gt;
&lt;p&gt;I returned from Marlow with new perspectives, collaborations, and reflextions. As I continue my doctoral research, I hope to integrate these insights into frameworks that help agents adapt, sustain fairness, and thrive together under disruption.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
