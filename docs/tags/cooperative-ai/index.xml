<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cooperative AI | Hugo Academic CV Theme</title><link>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/tags/cooperative-ai/</link><atom:link href="https://mavivi95.github.io/manuela_chacon_chamorro.github.io/tags/cooperative-ai/index.xml" rel="self" type="application/rss+xml"/><description>Cooperative AI</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 22 Oct 2025 00:00:00 +0000</lastBuildDate><image><url>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/media/icon_hu_982c5d63a71b2961.png</url><title>Cooperative AI</title><link>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/tags/cooperative-ai/</link></image><item><title>📚 Recommended Readings on Cooperative AI (Vol. 1)</title><link>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/post/lecturas_v1/</link><pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate><guid>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/post/lecturas_v1/</guid><description>&lt;p>Cooperative AI is not only a technical challenge but also a question about how to design systems that balance individual incentives and collective welfare. In this first edition, I share a selection of papers that shaped the way I think about cooperation, social dilemmas, and resilience in multi-agent systems.&lt;/p>
&lt;ul>
&lt;li>
&lt;ol>
&lt;li>Open Problems in Cooperative AI — Dafoe et al., 2021&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>This paper is a research roadmap. It identifies key open questions spanning cooperation between AIs, human–AI coordination, communication, and mechanism design.&lt;/p>
&lt;p>💡 Why read it: It&amp;rsquo;s the definitive starting point for researchers who want to contribute to Cooperative AI — outlining what remains unsolved and why it matters for global AI safety and governance&lt;/p>
&lt;div class="callout flex px-4 py-3 mb-6 rounded-md border-l-4 bg-orange-100 dark:bg-orange-900 border-orange-500"
data-callout="warning"
data-callout-metadata="">
&lt;span class="callout-icon pr-3 pt-1 text-orange-600 dark:text-orange-300">
&lt;svg height="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">&lt;path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z"/>&lt;/svg>
&lt;/span>
&lt;div class="callout-content dark:text-neutral-300">
&lt;div class="callout-title font-semibold mb-1">This page is under construction.&lt;br>&lt;/div>
&lt;div class="callout-body">&lt;p>I&amp;rsquo;m currently setting up this section — new posts coming soon! 🚧&lt;/p>&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>🤖 Reflections from the Cooperative AI Summer School 2025</title><link>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/post/summer-cai/</link><pubDate>Tue, 15 Jul 2025 00:00:00 +0000</pubDate><guid>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/post/summer-cai/</guid><description>&lt;h2 id="a-week-of-cooperation-learning-and-shared-curiosity">A week of cooperation, learning, and shared curiosity&lt;/h2>
&lt;h4 id="-overview">🌍 Overview&lt;/h4>
&lt;p>This summer, I had the opportunity to attend the Cooperative AI Summer School 2025, organized by the Cooperative AI Foundation. It took place in Marlow, UK — a quiet town surrounded by green landscapes, perfect for a week dedicated to deep discussions about AI, cooperation, and human values. The program combined academic sessions and collaborative activities, structured as:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Keynote lectures by leading researchers,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>One-to-one meetings and working groups,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Poster sessions on July 10–11,&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A final hands-on challenge session.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="-main-themes-that-inspired-me">💡 Main themes that inspired me&lt;/h4>
&lt;p>The school brought together researchers from diverse fields—spanning machine learning, game theory, philosophy, and the social sciences. Despite our different profiles and research agendas, we converged on a shared question:
&lt;em>How can we build AI systems that cooperate effectively with humans and with each other?&lt;/em>&lt;/p>
&lt;p>Talks ranged from the formal foundations of cooperation and mixed-motive games to the social and ethical dimensions of AI. I was especially inspired by sessions on emergent coordination, multi-agent learning under uncertainty, and resilient collective behaviors. The poster session was equally insightful: work on diplomatic games and AI-mediated negotiation—particularly with LLM-based agents—made clear where current AI capabilities are heading and what is at stake.&lt;/p>
&lt;p>This trajectory presents both opportunities and risks. It underscores the need to anticipate misalignment behaviors and to advance AI safety by designing systems that incentivize cooperative objectives, align with collective well-being, and support multisector progress across regions.&lt;/p>
&lt;h4 id="-poster-presentation-and-gif-competition">🧠 Poster Presentation and GIF Competition&lt;/h4>
&lt;p>During the poster sessions, I presented my work titled “Cooperative Resilience in Multi-Agent AI Systems: From Definition to Reward Inference.” The poster summarized my research agenda, which unfolds in four main stages: defining what resilience means within the scope of Cooperative AI; measuring this property in mixed-motive multi-agent systems; understanding what drives agents to exhibit—or fail to exhibit—resilient behavior, for example by inferring their underlying rewards or motivations from trajectories evaluated with a resilience metric; and finally, using those insights to design agents that encapsulate this property and foster system-level resilience. The first two stages — &lt;strong>definition&lt;/strong> and &lt;strong>measurement&lt;/strong> — were developed in detail in my
, which lays the theoretical and experimental foundation for this line of research.&lt;/p>
&lt;div class="poster-grid">
&lt;div class="poster-column gif-col">
&lt;img src="gif_animado.gif" alt="Winning GIF" class="poster-gif"/>
&lt;/div>
&lt;div class="poster-column">
&lt;img src="img2.jpg" alt="Presenting the poster" class="poster-photo"/>
&lt;/div>
&lt;/div>
&lt;div class="poster-button-container">
&lt;a class="poster-button" href="poster.pdf" target="_blank">📄 View Full Poster (PDF)&lt;/a>
&lt;/div>
&lt;h4 id="-final-day--collaborative-challenge">🧩 Final Day — Collaborative Challenge&lt;/h4>
&lt;p>In the final session, we participated in a hands-on challenge exploring agent properties such as truthfulness and information sharing. Our group proposed an approach to measure truthfulness by analyzing how agents omit relevant information — linking naturally with our ongoing research on cooperative resilience and behavioral inference. This session fostered interdisciplinary collaboration, connecting reinforcement learning, behavioral modeling, and ethics.&lt;/p>
&lt;p>This activity raised deep questions about systems with LLM agents. Truthfulness alone is hard to define—let alone guarantee—and it quickly connects to other, more human-like capacities we may be inadvertently promoting in artificial agents. In particular, the ability to &lt;strong>omit information&lt;/strong> is critical: agents might leave things out for strategic, safety-related, or purely accidental reasons. Detecting when omission occurs, and inferring the underlying motivation, becomes a central challenge for evaluation and governance.&lt;/p>
&lt;h4 id="-connecting-research-and-purpose">🤝 Connecting research and purpose&lt;/h4>
&lt;p>Beyond the technical depth, what struck me most was the &lt;strong>community&lt;/strong>. I met researchers and practitioners working on questions closely aligned with my own, and it was energizing to realize how many people around the world are pursuing similar ideas. I had the chance to speak with several of them—people who share a vision for cooperative, reliable AI—and those conversations were grounding and inspiring. The school fostered an open, reflective atmosphere that blended academic rigor with philosophical curiosity and deeply motivating.&lt;/p>
&lt;h4 id="-looking-forward">🌱 Looking forward&lt;/h4>
&lt;p>Attending the Cooperative AI Summer School was a truly inspiring experience, scientifically and personally. It strengthened my understanding of cooperation as a fundamental design principle in AI systems and allowed me to connect with the global Cooperative AI community, sharing ideas, building friendships, and finding common research goals.&lt;/p>
&lt;p>I returned from Marlow with new perspectives, collaborations, and reflextions. As I continue my doctoral research, I hope to integrate these insights into frameworks that help agents adapt, sustain fairness, and thrive together under disruption.&lt;/p></description></item><item><title>Cooperative Resilience in Artificial Intelligence Multi-Agent Systems</title><link>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/publications/tai-2025/</link><pubDate>Tue, 06 May 2025 00:00:00 +0000</pubDate><guid>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/publications/tai-2025/</guid><description>&lt;p>&lt;strong>Abstract.&lt;/strong> Resilience refers to the ability of systems to with-stand, adapt to, and recover from disruptive events. While studies on resilience have attracted significant attention across various research domains, the precise definition of this concept within the field of cooperative artificial intelligence remains unclear. This paper addresses this gap by proposing a clear definition of ‘cooperative resilience’ and outlining a methodology for its quantitative measurement. The methodology is validated in an environment with RL-based and LLM-augmented autonomous agents, subjected to environmental changes and the introduction of agents with unsustainable behaviors. These events are parameterized to create various scenarios for measuring cooperative resilience. The results highlight the crucial role of resilience metrics in analyzing how the collective system prepares for, resists, recovers from, sustains well-being, and transforms in the face of disruptions. These findings provide foundational insights into the definition, measurement, and preliminary analysis of cooperative resilience, offering significant implications for the broader field of AI. Moreover, the methodology and metrics developed here can be adapted to a wide range of AI applications, enhancing the reliability and effectiveness of AI in dynamic and unpredictable environments.&lt;/p></description></item><item><title>Resiliencia en sistemas multiagente y la experiencia de un doctorado</title><link>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/events/manizales/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mavivi95.github.io/manuela_chacon_chamorro.github.io/events/manizales/</guid><description/></item></channel></rss>