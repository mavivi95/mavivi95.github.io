<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications | Hugo Academic CV Theme</title>
    <link>https://example.com/publications/</link>
      <atom:link href="https://example.com/publications/index.xml" rel="self" type="application/rss+xml" />
    <description>Publications</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 06 May 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu_982c5d63a71b2961.png</url>
      <title>Publications</title>
      <link>https://example.com/publications/</link>
    </image>
    
    <item>
      <title>Cooperative Resilience in Artificial Intelligence Multi-Agent Systems</title>
      <link>https://example.com/publications/tai-2025/</link>
      <pubDate>Tue, 06 May 2025 00:00:00 +0000</pubDate>
      <guid>https://example.com/publications/tai-2025/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Abstract.&lt;/strong&gt; Resilience refers to the ability of systems to with-stand, adapt to, and recover from disruptive events. While studies on resilience have attracted significant attention across various research domains, the precise definition of this concept within the field of cooperative artificial intelligence remains unclear. This paper addresses this gap by proposing a clear definition of ‘cooperative resilience’ and outlining a methodology for its quantitative measurement. The methodology is validated in an environment with RL-based and LLM-augmented autonomous agents, subjected to environmental changes and the introduction of agents with unsustainable behaviors. These events are parameterized to create various scenarios for measuring cooperative resilience. The results highlight the crucial role of resilience metrics in analyzing how the collective system prepares for, resists, recovers from, sustains well-being, and transforms in the face of disruptions. These findings provide foundational insights into the definition, measurement, and preliminary analysis of cooperative resilience, offering significant implications for the broader field of AI. Moreover, the methodology and metrics developed here can be adapted to a wide range of AI applications, enhancing the reliability and effectiveness of AI in dynamic and unpredictable environments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reducing overfitting in ResNet with Adaptive Lipschitz regularization</title>
      <link>https://example.com/publications/jcam-2025/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://example.com/publications/jcam-2025/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Abstract.&lt;/strong&gt; This paper introduces Adaptive Lipschitz Bound Regularization with Random Constraints (LBA Regularization), a method designed to mitigate overfitting in residual neural networks by dynamically adjusting the regularization parameter based on the spectral norm of randomly selected layers. Unlike traditional regularization techniques such as L1, L2, Dropout, Early Stopping, and Batch Normalization, LBA leverages an adaptive approach that effectively constrains the Lipschitz bound while maintaining flexibility in deep learning architectures. To substantiate this method, an analysis of the Lipschitz properties in ResNet architectures was performed, offering theoretical insights into their impact on model stability and generalization. The method was evaluated in various neural architectures and datasets, including MNIST, CIFAR-10, and tabular data sets. The results demonstrate that LBA significantly reduces the gap between training and validation accuracy, leading to improved generalization performance. Furthermore, an adversarial robustness analysis against FGSM and PGD attacks confirmed that LBA maintains model stability under adversarial perturbations.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
